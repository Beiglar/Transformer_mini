{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc679de4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T02:07:47.720529Z",
     "iopub.status.busy": "2025-10-09T02:07:47.720334Z",
     "iopub.status.idle": "2025-10-09T02:07:48.393480Z",
     "shell.execute_reply": "2025-10-09T02:07:48.392868Z",
     "shell.execute_reply.started": "2025-10-09T02:07:47.720511Z"
    },
    "id": "cc679de4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import operator\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from flax import nnx\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from modular.tokenizer import MiniCharTok\n",
    "from modular.dataloader import MemmapDataLoader, read_all_text, write_dataset_streaming\n",
    "from modular.config import ModelConfig, LRConfig, DataSplitRatios\n",
    "from modular.training import create_model_and_optimizer, train_step, compute_val_loss\n",
    "from modular.utils import History, sample_from_model, write_sample_to_file, format_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a6910",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T02:07:48.511772Z",
     "iopub.status.busy": "2025-10-09T02:07:48.511511Z",
     "iopub.status.idle": "2025-10-09T02:07:51.198369Z",
     "shell.execute_reply": "2025-10-09T02:07:51.197509Z",
     "shell.execute_reply.started": "2025-10-09T02:07:48.511748Z"
    },
    "id": "203a6910",
    "outputId": "e9e4f147-440b-47b4-eafc-9f63e18005af",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Path Setup (must configure these) ---\n",
    "BASE_PROJECT_DIR = os.path.abspath(\".\")\n",
    "DATA_DIR = os.path.join(BASE_PROJECT_DIR, \"data\")\n",
    "\n",
    "# ASSUMPTION: Dataset is already unpacked here.\n",
    "UNPACKED_DATASET_DIR = r'/text_dataset'\n",
    "# ASSUMPTION: Tokenizer model files are in this directory.\n",
    "TOKENIZER_DIR = os.path.join(BASE_PROJECT_DIR, \"tokenizer_model\")\n",
    "SAMPLES_DIR = os.path.join(BASE_PROJECT_DIR, \"training_samples\")\n",
    "OUTPUT_RECORD_FILE = os.path.join(SAMPLES_DIR, 'HT_training_log.txt')\n",
    "TOKEN_ID_DIR = os.path.join(BASE_PROJECT_DIR, \"token_ids\")\n",
    "\n",
    "os.makedirs(TOKEN_ID_DIR, exist_ok=True) # For token ids\n",
    "os.makedirs(SAMPLES_DIR, exist_ok=True) # For logs and plots\n",
    "\n",
    "raw_text_corpus = read_all_text(UNPACKED_DATASET_DIR)[:800000]\n",
    "if not raw_text_corpus: print(f\"Error: No text data found in {UNPACKED_DATASET_DIR}. Exiting.\")\n",
    "\n",
    "corpus_char_length = len(raw_text_corpus)\n",
    "print(f\"Total characters in dataset after preprocessing: {corpus_char_length:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6a83b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T02:07:51.199509Z",
     "iopub.status.busy": "2025-10-09T02:07:51.199271Z",
     "iopub.status.idle": "2025-10-09T02:08:16.742761Z",
     "shell.execute_reply": "2025-10-09T02:08:16.741889Z",
     "shell.execute_reply.started": "2025-10-09T02:07:51.199491Z"
    },
    "id": "cc6a83b7",
    "outputId": "dd903f5e-7ebd-4e13-a5bb-6b42f994fb45",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define special tokens: PAD and UNK\n",
    "special = {'<PAD>': 0, '<UNK>': 1}\n",
    "\n",
    "# Initialize tokenizer with min_freq=4 (only keep chars appearing â‰¥4 times)\n",
    "tokenizer = MiniCharTok(special, min_freq=4)\n",
    "tokenizer(raw_text_corpus)\n",
    "VOCAB_SIZE = tokenizer.GetPieceSize()\n",
    "pad_token_id = special['<PAD>']\n",
    "context_length = 64\n",
    "batch_size = 512\n",
    "\n",
    "dsr = DataSplitRatios(train=0.95, valid=.05)\n",
    "train_end, valid_end = dsr(corpus_char_length)\n",
    "train_data_text = raw_text_corpus[:train_end]\n",
    "valid_data_text = raw_text_corpus[train_end:valid_end]\n",
    "\n",
    "train_tokens_path = write_dataset_streaming(train_data_text, tokenizer, os.path.join(TOKEN_ID_DIR, \"train_token_ids\"), dtype=np.uint16)\n",
    "valid_tokens_path = write_dataset_streaming(valid_data_text, tokenizer, os.path.join(TOKEN_ID_DIR, \"valid_token_ids\"), dtype=np.uint16)\n",
    "\n",
    "train_token_loader = MemmapDataLoader(token_ids_path=train_tokens_path, max_seq_len=context_length, batch_size=batch_size)\n",
    "valid_token_loader = MemmapDataLoader(token_ids_path=valid_tokens_path, max_seq_len=context_length, batch_size=batch_size)\n",
    "\n",
    "print(f\"Train data: ~{len(train_token_loader):,} sample batches. Validation data: ~{len(valid_token_loader):,} sample batches.\")\n",
    "print(f\"Tokenizer ready. Actual vocabulary size: {VOCAB_SIZE}. Pad ID: {pad_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a6a02",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T02:16:24.250012Z",
     "iopub.status.busy": "2025-10-09T02:16:24.249655Z",
     "iopub.status.idle": "2025-10-09T02:16:25.570175Z",
     "shell.execute_reply": "2025-10-09T02:16:25.569389Z",
     "shell.execute_reply.started": "2025-10-09T02:16:24.249989Z"
    },
    "id": "2b8a6a02",
    "outputId": "4e10fce2-4b93-428c-e39c-fe817277b577",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "num_batches_per_epoch = len(train_token_loader)\n",
    "total_steps = num_epochs * num_batches_per_epoch\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "key = jax.random.PRNGKey(0) # for sampling\n",
    "\n",
    "lr_config = LRConfig(warmup_steps=warmup_steps, decay_steps=total_steps - warmup_steps)\n",
    "train_history =  History()\n",
    "\n",
    "model, optimizer, schedule = create_model_and_optimizer(\n",
    "    model_config=ModelConfig(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        dim=128,\n",
    "        num_layers=2,\n",
    "        num_heads=8,\n",
    "        mlp_ratio=2.0,\n",
    "        dropout=0.2,\n",
    "        context_size=context_length,\n",
    "        rngs=nnx.Rngs(0)\n",
    "    ),\n",
    "    lr_config=lr_config\n",
    ")\n",
    "nnx.display(model)\n",
    "p_sizes = jax.tree.map(lambda p: p.size if isinstance(p, jnp.ndarray) else 0, nnx.state(model, nnx.Param))\n",
    "p_count = jax.tree.reduce(operator.add, p_sizes)\n",
    "expected_untrained_loss = -math.log(1/VOCAB_SIZE)\n",
    "print(\n",
    "    f'expected untrained loss: {expected_untrained_loss:.3f}\\n'\n",
    "    f'model parameter count: {p_count}\\n'\n",
    "    f'# of batches per epoch: {num_batches_per_epoch:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fce2b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T02:16:35.173873Z",
     "iopub.status.busy": "2025-10-09T02:16:35.173570Z"
    },
    "id": "16fce2b3",
    "outputId": "19d3c74e-4c6c-46fe-f66a-a8ddf4dc9452",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "\n",
    "    # --- Training Phase ---\n",
    "    for batch_idx, batch in enumerate(train_token_loader):\n",
    "        step = epoch * num_batches_per_epoch + batch_idx\n",
    "        current_lr = float(schedule(step))\n",
    "        loss = train_step(model, optimizer, batch)\n",
    "        train_history(loss.item(), current_lr)\n",
    "\n",
    "        # Log training progress periodically\n",
    "        is_last_batch = (batch_idx + 1) == num_batches_per_epoch\n",
    "        if batch_idx % 100 == 0 or is_last_batch:\n",
    "            # Generate a sample and format the report\n",
    "            sample = sample_from_model(model, \"The meaning of life is\", tokenizer, rng=key, max_new_tokens=64)\n",
    "            report_str = format_report(epoch+1, step+1, train_history.report(), sample)\n",
    "            print(report_str)\n",
    "            write_sample_to_file(OUTPUT_RECORD_FILE, report_str)\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    avg_val_loss = np.mean(compute_val_loss(model, valid_token_loader))\n",
    "    train_history.val_loss.append(avg_val_loss)\n",
    "\n",
    "    epoch_duration = time.time() - epoch_start_time\n",
    "    print(f\"Epoch {epoch+1} completed in {epoch_duration:.2f} seconds.\")\n",
    "    print(f\"Average validation loss: {avg_val_loss:.4f}\")\n",
    "    write_sample_to_file(OUTPUT_RECORD_FILE, f\"Epoch {epoch+1} Validation Loss: {avg_val_loss:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8434084,
     "sourceId": 13305789,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
